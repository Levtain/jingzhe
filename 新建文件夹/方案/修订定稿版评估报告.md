# 惊蛰计划"修订定稿版"方案评估报告

> **评估日期**: 2025-01-07
> **评估人**: 老黑(Claude)
> **评估目标**: 分析修订定稿版方案对惊蛰计划的适用性

---

## 📊 方案背景分析

### 方案来源
这个"修订定稿版"是对之前三个方案的综合融合:
- ✅ 以 **DRB-Rank** 为主框架(双轨鲁棒加权贝叶斯)
- ✅ 融合 **DTSRM** 的活跃权重思想
- ✅ 融合 **DWJ** 的双侧截尾优势
- ❌ 删除了"信誉系统"等首届不具备条件的要素

### 与惊蛰计划的契合度检查

让我逐项对比惊蛰计划的核心特征:

| 惊蛰计划特征 | 修订定稿版方案 | 契合度 |
|------------|--------------|--------|
| **第一届比赛** | 无需历史数据,适配第一届 | ✅✅ 完美契合 |
| **12个独立榜单** | 双轨排名(评委榜+玩家榜) | ⚠️ 部分契合 |
| **6个评分维度** | 统一评分维度设计 | ✅ 完全契合 |
| **不计算总分** | **有综合总榜** | ❌ **冲突** |
| **评审团权重×2** | 未体现权重×2 | ⚠️ 未明确 |
| **排名门槛>20人次** | 无门槛机制 | ❌ 缺失 |
| **可解释性要求高** | 对外简化版,内部复杂 | ⚠️ 部分满足 |

---

## 🚨 核心冲突分析

### 冲突1: 综合总榜 vs 不计算总分

**惊蛰计划的核心设计理念**:
> ✅ **不计算总分**: 不存在"总分排名"
> ✅ **各维度独立**: 每个维度单独计算排名
> ✅ **无权重争议**: 避免"哪个维度更重要"的争论

**修订定稿版方案**:
> ❌ 第49行: "总榜为**加权综合得分**,所用权重公开透明"

**这是直接冲突!**

---

### 冲突2: 12榜单 vs 双轨排名

**惊蛰计划的12榜单架构**:
```
6个维度 × 2个评分群体 = 12个独立榜单
├── 创新性（参赛者榜）
├── 创新性（评审团榜）
├── 主题诠释（参赛者榜）
├── 主题诠释（评审团榜）
├── 视觉效果（参赛者榜）
├── 视觉效果（评审团榜）
├── 音乐音频（参赛者榜）
├── 音乐音频（评审团榜）
├── 整体性（参赛者榜）
├── 整体性（评审团榜）
├── 有活儿（参赛者榜）
└── 有活儿（评审团榜）
```

**修订定稿版的双轨架构**:
```
玩家榜 (Player Rank)
├── 创意维度
├── 玩法维度
├── 美术维度
├── 音效维度
├── 叙事维度
└── 完成度维度
└── **综合总榜** ❌

评委榜 (Judge Rank)
├── 创意维度
├── 玩法维度
├── 美术维度
├── 音效维度
├── 叙事维度
└── 完成度维度
└── **综合总榜** ❌
```

**差异**:
- 惊蛰计划: **12个榜单**,无总榜
- 修订定稿版: **14个榜单**(2个总榜)

---

### 冲突3: 评审团权重×2的缺失

**惊蛰计划规则**:
```
总评分人次 = 参赛者评分人次 + 2 × 评审团评分人次
```
评审团的1次评分 = 参赛者的2次评分

**修订定稿版方案**:
- ✅ 双轨独立设计(评委榜+玩家榜)
- ❌ **未提及评审团权重×2**

**问题**: 评审团的权重体现在哪里?
- 如果只是独立榜单,那权重×2在哪里体现?
- 如果在综合总榜中体现,那又违反了"不计算总分"原则

---

### 冲突4: 排名门槛的缺失

**惊蛰计划规则**:
```
总评分人次 > 20 才能进入排名
```

**修订定稿版方案**:
- ✅ 有贝叶斯平滑(冷启动保护)
- ❌ **没有硬性门槛规则**

**差异**:
- 惊蛰计划: 硬性门槛(<20人次不排名)
- 修订定稿版: 软性平滑(评分少时拉向均值)

---

## ✅ 优点分析

### 1. 公平性极强

**多层防护机制**:
- ✅ 用户贡献权重: W = 1 + ln(1+n)
- ✅ 双侧截尾: 去掉最高最低10%
- ✅ 鲁棒均值(Huber): 抗极端值
- ✅ 贝叶斯平滑: 冷启动保护
- ✅ 争议度惩罚: 标准差调整

**抗刷分能力**: ⭐⭐⭐⭐⭐ (极强)

---

### 2. 科学严谨

**成熟的统计学方法**:
- 鲁棒均值(Huber Mean) - 学术界认可
- 贝叶斯平滑 - 经典的冷启动方法
- 标准差惩罚 - 识别争议作品

**学术支撑**: ⭐⭐⭐⭐⭐

---

### 3. 无需历史数据

**第一届即可运行**:
- ✅ 不依赖历届数据
- ✅ 不需要信誉系统
- ✅ 不需要行为特征数据
- ✅ 仅使用当前届评分数据

**第一届适配性**: ⭐⭐⭐⭐⭐

---

## ❌ 缺陷分析

### 1. 可解释性差 (致命缺陷)

**征集要求**:
> 参赛者能理解为什么自己排这个名次

**修订定稿版的算法**:
```
原始评分 → 用户贡献权重 → 双侧截尾 → 鲁棒均值 → 贝叶斯平滑 → 争议度惩罚 = 最终得分
```

**参赛者能理解吗?**
- ❌ "鲁棒均值"是什么?
- ❌ "贝叶斯平滑"怎么算?
- ❌ "争议度惩罚"为什么减分?
- ❌ "自然对数权重"怎么来的?

**对外简化版** (第299-313行):
> 1. 评委榜与玩家榜分开算
> 2. 极端分会被剔除
> 3. 小样本不会直接冲榜
> 4. 分歧大的作品会下调
> 5. 多评价的玩家影响更大

**问题**:
- 这只是"简化版",不是"完整版"
- 参赛者手算无法复现结果
- 可能被质疑"黑箱操作"

**可解释性**: ⭐⭐ (差)

---

### 2. 计算复杂度高

**实现复杂度**: ⭐⭐⭐⭐⭐ (极高)

**难点**:
1. **鲁棒均值(Huber)需要迭代求解**
   - 不能直接公式计算
   - 需要数值优化算法
   - 计算时间不确定

2. **贝叶斯平滑需要全平台均值μ**
   - 需要先计算所有游戏
   - 然后才能计算单个游戏
   - 依赖计算顺序

3. **标准差惩罚**
   - 需要额外的统计计算
   - 增加计算步骤

**估算工作量**: 5-7人日 (远超DWJ的1-2人日)

---

### 3. 参数过多,难以调优

**需要确定的参数**:
- α (截尾比例): 10% 或 15%
- k (贝叶斯平滑强度): 10-20 或 20-25
- λ (争议惩罚权重): 0.2-0.4
- Huber损失的δ参数: 未给出建议值

**问题**:
- 第一届没有历史数据
- 无法通过AB测试确定最优参数
- 参数设置依赖"经验"或"猜测"

**风险**: 参数设置不当可能严重影响排名公平性

---

### 4. 与惊蛰计划核心设计冲突

**核心冲突总结**:
1. ❌ **综合总榜** vs 不计算总分
2. ❌ **14个榜单** vs 12个榜单
3. ❌ **无门槛规则** vs >20人次门槛
4. ❌ **评审团权重×2未体现**

**适配难度**: ⚠️⚠️⚠️ 需要大量修改

---

## 📊 与三个原始方案对比

| 维度 | DWJ | DTSRM | DRB-Rank | 修订定稿版 |
|------|-----|-------|----------|-----------|
| **公平性** | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **可解释性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐ |
| **第一届可行性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| **计算复杂度** | ⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **与惊蛰计划契合度** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| **综合评分** | **90/100** | 77/100 | 73/100 | **68/100** |

**说明**:
- 修订定稿版虽然公平性最强,但**与惊蛰计划的契合度最差**
- 核心原因是: **引入了综合总榜**,违背了惊蛰计划的核心理念

---

## 🎯 最终评估

### 如果直接使用修订定稿版

**优点**:
- ✅ 公平性最强
- ✅ 科学严谨
- ✅ 抗刷分能力极强

**缺点**:
- ❌ **与惊蛰计划核心理念冲突**(综合总榜)
- ❌ **可解释性差**
- ❌ **实现复杂度高**(5-7人日)
- ❌ **参数过多,难以调优**
- ❌ **参赛者可能质疑"黑箱操作"**

**适配工作量**: 需要大量修改才能符合惊蛰计划要求

---

### 推荐方案: 混合方案

结合修订定稿版的优点,但保持惊蛰计划的核心设计:

#### 混合方案架构

**保留修订定稿版的**:
1. ✅ 用户贡献权重: W = 1 + ln(1+n)
2. ✅ 双侧截尾: 去掉最高最低10%
3. ✅ 贝叶斯平滑: (n×S + k×μ)/(n+k) (可选,第二届引入)

**删除修订定稿版的**:
1. ❌ 综合总榜
2. ❌ 鲁棒均值(Huber) - 改用简单截尾均值
3. ❌ 争议度惩罚(标准差) - 第一届不需要

**符合惊蛰计划的**:
1. ✅ 12个独立榜单
2. ✅ 不计算总分
3. ✅ 排名门槛>20人次
4. ✅ 评审团权重×2(在门槛中体现)

#### 混合方案算法

```python
def hybrid_score(game, dimension, scorer_group):
    """
    混合方案: 结合修订定稿版的优点,但符合惊蛰计划设计
    """
    scores = get_scores(game, dimension, scorer_group)

    # 1. 用户贡献权重(来自修订定稿版)
    weights = [1 + ln(1 + user.score_count) for user in scores.users]
    weighted_scores = [score * weight for score, weight in zip(scores, weights)]

    # 2. 双侧截尾(来自修订定稿版)
    if len(weighted_scores) >= 10:
        k = max(1, int(len(weighted_scores) * 0.1))
        trimmed = sorted(weighted_scores)[k:-k]
    else:
        trimmed = weighted_scores

    # 3. 简单算术平均(不使用Huber)
    final_score = sum(trimmed) / len(trimmed)

    return final_score
```

#### 混合方案优势

| 特性 | 修订定稿版 | 混合方案 |
|------|-----------|---------|
| 公平性 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| 可解释性 | ⭐⭐ | ⭐⭐⭐⭐ |
| 第一届可行性 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| 计算复杂度 | ⭐⭐⭐⭐⭐ | ⭐⭐ |
| 与惊蛰计划契合度 | ⭐⭐ | ⭐⭐⭐⭐⭐ |
| **综合评分** | **68/100** | **85/100** |

---

## 💡 最终建议

### 方案A: 第一届用DWJ,第二届用混合方案 ⭐⭐⭐⭐⭐

**第一届**: 使用DWJ方案
- 可解释性完美
- 实现简单(1-2人日)
- 符合惊蛰计划12榜单架构

**第二届**: 升级到混合方案
- 引入用户贡献权重
- 引入双侧截尾
- 保持可解释性

**优势**:
- 第一届稳妥可靠
- 第二届逐步优化
- 符合惊蛰计划长期发展

---

### 方案B: 直接使用混合方案 ⭐⭐⭐⭐

**第一届就用混合方案**:
- 引入用户权重(鼓励多评分)
- 保留简单算术平均(可解释)
- 完全符合惊蛰计划设计

**优势**:
- 公平性比DWJ好
- 可解释性比修订定稿版好
- 实现复杂度中等(2-3人日)

---

### 方案C: 使用修订定稿版但大幅修改 ⭐⭐

**修改点**:
1. 删除综合总榜
2. 删除Huber鲁棒均值
3. 删除争议度惩罚
4. 增加12榜单架构
5. 增加排名门槛规则

**问题**: 修改后就不再是"修订定稿版"了,基本等同于混合方案

---

## 📋 总结

### 修订定稿版方案的定位

**修订定稿版是一个优秀的通用Game Jam排名方案**,但:
- ❌ **不适合直接用于惊蛰计划**
- ✅ **核心思想值得借鉴**(用户权重、双侧截尾、贝叶斯平滑)
- ⚠️ **需要大量修改才能符合惊蛰计划要求**

### 最佳实践建议

**第一届**: 使用混合方案(修订定稿版的简化版)
- 用户权重: W = 1 + ln(1+n)
- 双侧截尾: 10%
- 简单算术平均: 保持可解释性
- 符合12榜单架构
- 符合>20人次门槛

**第二届**: 引入更多机制
- 贝叶斯平滑(冷启动保护)
- 动态截尾比例
- 保留用户权重

**第三届+**: 根据数据优化
- 根据前两届数据调整参数
- 可能引入更复杂的鲁棒方法
- 但始终保持可解释性

---

## 🎯 最终答案

**问题**: 修订定稿版方案是否适合惊蛰计划?

**答案**: ⚠️⚠️⚠️ **不适合直接使用**

**原因**:
1. ❌ 引入综合总榜,违背惊蛰计划核心理念
2. ❌ 可解释性差,参赛者难以理解
3. ❌ 计算复杂度高,第一届风险大
4. ❌ 参数过多,无历史数据难以调优

**建议**: ✅ 使用**混合方案**(融合修订定稿版的优点,但保持简单)

**混合方案特点**:
- ✅ 保留用户权重(鼓励多评分)
- ✅ 保留双侧截尾(抗刷分)
- ✅ 删除Huber/贝叶斯/争议惩罚(保持简单)
- ✅ 符合12榜单架构
- ✅ 符合>20人次门槛
- ✅ 可解释性强(一句话可说明)

---

*评估人: 老黑(Claude)*
*评估日期: 2025-01-07*
*版本: v1.0*
