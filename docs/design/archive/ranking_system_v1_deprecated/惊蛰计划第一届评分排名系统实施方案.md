# 惊蛰计划第一届评分排名系统实施方案

## 一、核心设计原则

### 1.1 基本理念

**“透明优于复杂，稳定优于完美”**  
第一届的核心目标是：建立可信赖的排名系统，收集真实数据，验证基本假设，为后续迭代奠定基础。

### 1.2 三大支柱

1. **可解释性**：每个计算步骤都能用一句话向用户解释清楚

2. **抗扰动性**：能抵御常见刷分行为，但不追求完美防御

3. **渐进公平**：承认第一届的不完美，但确保基本公平，并承诺持续改进

## 二、完整实施架构

### 2.1 系统流程图

text

用户评分
    ↓
[预处理层]
├── 自评过滤（自动）
├── 高危行为标记（自动+人工复核）
└── 基础完整性检查
    ↓
[资格判定层] → 未达门槛 → 显示“未达排名门槛”
    ↓
[计算核心层]
├── 截尾均值（去极端值）
├── 贝叶斯平滑（防小样本偏差）
└── 并列裁决
    ↓
[输出层]
├── 各维度独立排名
├── “优选游戏”标识
└── 用户可见的得分解释

### 2.2 详细算法规范

#### **第一步：数据收集与预处理**

python

def preprocess_ratings(game_id, dimension, raw_ratings):
    """
    预处理评分数据
    返回：(有效评分列表, 标记为可疑的评分列表, 总有效人次)
    """
    valid_ratings = []
    suspicious_ratings = []

    for rating in raw_ratings:
        # 规则1：排除自评
        if rating.rater_id == game.creator_id:
            continue
    
        # 规则2：高危行为标记（仅标记，不自动排除）
        if is_high_risk_behavior(rating.rater_id):
            suspicious_ratings.append(rating)
            # 第一届：标记后仍计入，但记录审计日志
            valid_ratings.append(rating)
            continue
    
        # 规则3：完整性检查
        if not (1 <= rating.score <= 10):  # 假设10分制
            continue
    
        valid_ratings.append(rating)
    
    # 计算有效人次（评审团×2）
    contestant_count = len([r for r in valid_ratings if r.rater_type == 'contestant'])
    jury_count = len([r for r in valid_ratings if r.rater_type == 'jury'])
    total_effective_ratings = contestant_count + 2 * jury_count
    
    return valid_ratings, suspicious_ratings, total_effective_ratings

#### **第二步：排名资格判定**

python

def check_ranking_eligibility(total_effective_ratings, config):
    """
    检查是否具备排名资格
    """
    MIN_RATINGS = config['min_ratings']  # 建议：20人次

    if total_effective_ratings < MIN_RATINGS:
        return {
            'eligible': False,
            'reason': f'评分人次不足（需要{MIN_RATINGS}，实际{total_effective_ratings}）',
            'actual_count': total_effective_ratings
        }
    return {'eligible': True}

#### **第三步：截尾均值计算（抗极端值）**

python

def winsorized_mean(scores, trim_percent=0.1):
    """
    计算截尾均值

    设计选择说明：
    1. 不直接用中位数：保留更多信息
    2. 不用Huber Mean：避免迭代收敛问题
    3. 固定10%截断：简单可解释
    """
    n = len(scores)
    
    # 小样本保护：样本少于10个时不截断
    if n < 10:
        return sum(scores) / n, {'method': 'arithmetic_mean', 'trimmed': 0}
    
    # 确定截断数量
    k = int(n * trim_percent)
    
    # 特殊情况处理
    if k == 0 and n >= 10:
        k = 1  # 至少截掉1个最高分和1个最低分
    
    # 排序并截断
    sorted_scores = sorted(scores)
    trimmed_scores = sorted_scores[k:n-k]
    
    # 计算均值
    result = sum(trimmed_scores) / len(trimmed_scores)
    
    return result, {
        'method': 'winsorized_mean',
        'trim_percent': trim_percent,
        'trimmed_count': 2 * k,
        'original_count': n,
        'remaining_count': len(trimmed_scores)
    }

#### **第四步：贝叶斯平滑（防小样本偏差）**

python

def bayesian_smoothing(robust_mean, rating_count, global_mean, config):
    """
    贝叶斯平滑：小样本向全局均值回归

    参数选择理由：
    k=20 意味着：需要20个评分才能摆脱全局均值的一半影响
    对于50-200人的比赛，20是一个合理的"可信样本"阈值
    """
    k = config['bayesian_k']  # 建议：20
    
    if rating_count == 0:
        return global_mean, {'method': 'global_mean_only', 'k': k}
    
    # 计算平滑后分数
    smoothed = (rating_count * robust_mean + k * global_mean) / (rating_count + k)
    
    return smoothed, {
        'method': 'bayesian_smoothing',
        'k': k,
        'global_mean': global_mean,
        'influence_ratio': k / (rating_count + k),  # 全局均值的影响比例
        'robust_mean': robust_mean
    }

#### **第五步：并列处理规则**

python

def break_ties(game_a, game_b, tie_breaker_config):
    """
    并列处理规则（仅在最终得分差值小于epsilon时触发）

    设计理念：
    1. 不修改分数本身，只影响排名顺序
    2. 明确的优先级顺序
    3. 最终可接受并列
    """
    EPSILON = 0.001  # 认为得分差异小于此值时属于并列
    
    score_diff = abs(game_a['final_score'] - game_b['final_score'])
    if score_diff >= EPSILON:
        return None  # 不是并列，按分数排序
    
    # Tie-breaker 1: 评分人数多的优先
    if game_a['rating_count'] != game_b['rating_count']:
        return 'A' if game_a['rating_count'] > game_b['rating_count'] else 'B'
    
    # Tie-breaker 2: 方差小的优先（更稳定）
    if game_a['variance'] != game_b['variance']:
        return 'A' if game_a['variance'] < game_b['variance'] else 'B'
    
    # Tie-breaker 3: 评审团评分占比高的优先
    jury_ratio_a = game_a['jury_count'] / game_a['rating_count'] if game_a['rating_count'] > 0 else 0
    jury_ratio_b = game_b['jury_count'] / game_b['rating_count'] if game_b['rating_count'] > 0 else 0
    
    if abs(jury_ratio_a - jury_ratio_b) > 0.01:  # 1%差异阈值
        return 'A' if jury_ratio_a > jury_ratio_b else 'B'
    
    # 所有条件都相同 -> 允许并列
    return 'tie'

### 2.3 全局计算流程

python

def calculate_dimension_ranking(all_games, dimension, config):
    """
    计算单个维度的完整排名
    """
    results = []

    # 步骤1：计算全局统计量（仅基于有资格排名的游戏）
    eligible_games = []
    for game in all_games:
        valid_ratings, _, total_effective = preprocess_ratings(
            game.id, dimension, game.ratings[dimension]
        )
    
        if check_ranking_eligibility(total_effective, config)['eligible']:
            eligible_games.append({
                'game': game,
                'valid_ratings': valid_ratings,
                'total_effective': total_effective
            })
    
    # 计算该维度的全局均值（基于截尾均值）
    robust_means = []
    for data in eligible_games:
        scores = [r.score for r in data['valid_ratings']]
        robust_mean, _ = winsorized_mean(scores, config['trim_percent'])
        robust_means.append(robust_mean)
    
    global_mean = sum(robust_means) / len(robust_means) if robust_means else config['default_global_mean']
    
    # 步骤2：计算每个游戏的最终得分
    for data in eligible_games:
        game = data['game']
        scores = [r.score for r in data['valid_ratings']]
    
        # 2.1 计算鲁棒均值
        robust_mean, winzorized_info = winsorized_mean(scores, config['trim_percent'])
    
        # 2.2 贝叶斯平滑
        final_score, smoothing_info = bayesian_smoothing(
            robust_mean, 
            len(scores),  # 注意：这里是评分人数，不是人次
            global_mean, 
            config
        )
    
        # 2.3 收集统计信息
        results.append({
            'game_id': game.id,
            'game_name': game.name,
            'final_score': final_score,
            'raw_mean': sum(scores) / len(scores) if scores else 0,
            'robust_mean': robust_mean,
            'rating_count': len(scores),  # 评分人数
            'effective_rating_count': data['total_effective'],  # 评分人次（评审团×2）
            'jury_count': len([r for r in data['valid_ratings'] if r.rater_type == 'jury']),
            'variance': np.var(scores) if len(scores) > 1 else 0,
            'metadata': {
                'winzorized_info': winzorized_info,
                'smoothing_info': smoothing_info,
                'global_mean': global_mean
            }
        })
    
    # 步骤3：排序（应用并列处理）
    sorted_results = sorted(results, key=lambda x: x['final_score'], reverse=True)
    
    # 应用tie-breaker
    i = 0
    while i < len(sorted_results) - 1:
        tie_result = break_ties(sorted_results[i], sorted_results[i+1], config)
    
        if tie_result == 'B':
            # 交换位置
            sorted_results[i], sorted_results[i+1] = sorted_results[i+1], sorted_results[i]
            # 可能需要继续向前检查
            if i > 0:
                i -= 1
            continue
        elif tie_result == 'tie':
            # 标记为并列
            sorted_results[i]['is_tie'] = True
            sorted_results[i+1]['is_tie'] = True
    
        i += 1
    
    # 步骤4：分配名次（考虑并列）
    rank = 1
    for i, result in enumerate(sorted_results):
        if i > 0 and not result.get('is_tie', False):
            rank = i + 1
    
        result['rank'] = rank
        if result.get('is_tie', False):
            result['rank_display'] = f"T-{rank}"
        else:
            result['rank_display'] = str(rank)
    
    return sorted_results

## 三、配置参数与调优指南

### 3.1 推荐配置（第一届）

yaml

ranking_config:

# 资格门槛

  min_ratings: 20  # 最低评分人次

# 截尾均值

  trim_percent: 0.1  # 去掉最高和最低各10%
  min_samples_for_trim: 10  # 少于10个评分时不截断

# 贝叶斯平滑

  bayesian_k: 20  # 平滑强度参数
  default_global_mean: 7.0  # 默认全局均值（当无数据时使用）

# 并列处理

  tie_epsilon: 0.001  # 视为并列的分数差异阈值

# 特殊处理

  enable_jury_weight: false  # 第一届：评审团评分在计算平均分时不加权
  enable_rts: false  # 第一届：不使用评分者信誉系统

### 3.2 参数调优逻辑

1. **赛前预设**：使用上述推荐值

2. **赛中监控**：实时查看以下指标：
   
   - 被截断的评分比例（如果>20%，考虑降低trim_percent）
   
   - 贝叶斯平滑影响度（如果大部分游戏被显著调整，考虑调整k值）
   
   - 未达门槛游戏比例（如果>30%，考虑降低min_ratings）

3. **赛后复盘**：基于实际数据重新校准所有参数

## 四、用户解释与透明度设计

### 4.1 得分解释卡片（UI展示）

text

作品《游戏名称》在【创新性】维度：
基础计算：
• 共收到47个有效评分（其中评审团评分3个）
• 去掉最高4个和最低4个评分（截尾10%）
• 剩余39个评分的平均分：8.42分
贝叶斯平滑：
• 该维度全局平均分：7.15分
• 由于您的评分数量(47)较多，平滑调整影响很小
• 最终得分：8.39分
当前排名：第3名（与第2名得分差0.05分）

### 4.2 常见问题官方解答

**Q1：为什么我的分数和直接平均分不一样？**

> 我们使用了"截尾均值"算法，自动去除了最高和最低各10%的可能异常评分，这能防止恶意刷分对您作品的影响。具体去除了哪些评分不公开，以避免针对性攻击。

**Q2：评分人数少会吃亏吗？**

> 对于评分人数较少的作品，我们会用"贝叶斯平滑"算法，适当参考全局平均水平进行调整。这能避免偶然的高分或低分对排名产生过大影响。随着评分人数增加，这种调整会越来越小。

**Q3：评审团的评分权重更高吗？**

> 在计算"评分人次"时，每个评审团评分按2人次计算，这能帮助作品更快达到排名门槛。但在计算平均分时，评审团评分和参赛者评分权重相同。

**Q4：如果两人分数相同，谁排前面？**

> 我们会依次比较：1) 评分人数多的优先；2) 评分更稳定的优先（方差小）；3) 评审团评分占比高的优先。如果这些都相同，则允许并列排名。

## 五、工程实施清单

### 5.1 开发任务分解（8人日）

| 任务         | 工作量  | 负责人   | 交付物           | 验收标准                |
| ---------- | ---- | ----- | ------------- | ------------------- |
| 1. 评分预处理模块 | 1.5天 | 后端    | 评分过滤API       | 通过单元测试，覆盖自评、高危标记等场景 |
| 2. 截尾均值算法  | 1天   | 后端    | 计算函数+测试       | 正确处理边界情况（小样本、极端分布）  |
| 3. 贝叶斯平滑算法 | 1天   | 后端    | 计算函数+测试       | 参数可配置，性能达标          |
| 4. 并列处理逻辑  | 0.5天 | 后端    | tie-breaker函数 | 处理所有并列场景            |
| 5. 排名批处理任务 | 1.5天 | 后端    | 排名计算Job       | 支持定时触发，性能满足要求       |
| 6. 数据监控看板  | 1.5天 | 数据工程师 | Grafana看板     | 包含评分分布、算法影响度等关键指标   |
| 7. 降级开关实现  | 0.5天 | SRE   | 配置开关          | 可一键切换为简单平均算法        |
| 8. 用户解释文档  | 0.5天 | 产品    | FAQ页面         | 用户测试通过，无歧义          |

### 5.2 监控指标定义

python

监控指标 = {
    'algorithm_health': {
        'winsorize_impact': '截尾算法影响的评分比例',
        'bayesian_adjustment': '贝叶斯平滑的平均调整幅度',
        'tie_occurrence': '发生并列的频率',
    },
    'system_fairness': {
        'rating_distribution': '评分分布（是否正态）',
        'cold_start_issue': '高质量低评分作品数量',
        'complaint_rate': '排名相关投诉率',
    },
    'performance': {
        'ranking_compute_time': '排名计算耗时',
        'api_response_time': '排名查询接口耗时',
        'memory_usage': '计算过程内存使用',
    }
}

### 5.3 降级与容灾方案

**降级策略**（按优先级）：

1. **Level 1**：关闭贝叶斯平滑，仅使用截尾均值

2. **Level 2**：关闭截尾均值，使用简单算术平均

3. **Level 3**：使用预计算的静态排名（手动上传）

**触发条件**：

- 连续3次排名计算失败

- 用户投诉率超过5%

- 系统负载超过阈值持续10分钟

## 六、第一届后评估与迭代路线

### 6.1 必做数据分析

比赛结束后2周内，完成以下分析：

python

分析报告 = {
    '第一部分：算法效果验证': [
        '截尾均值去除了多少极端评分？这些评分是真的异常吗？',
        '贝叶斯平滑对多少作品产生了显著影响（>0.5分）？',
        '并列处理规则实际触发了多少次？是否合理？',
    ],
    '第二部分：公平性评估': [
        '有多少高质量作品因评分不足未进入排名？',
        '评审团评分与大众评分的一致性如何？',
        '是否有作品受到明显的恶意评分攻击？',
    ],
    '第三部分：用户体验': [
        '用户对排名规则的投诉主要集中在哪些方面？',
        '用户是否理解我们的算法解释？',
        '有多少用户认为排名结果公平？',
    ]
}

### 6.2 第二届优化建议（基于数据驱动）

**如果发现以下问题**：

1. **极端评分过多** → 考虑引入Huber Mean或调整截断比例

2. **冷启动问题严重** → 考虑引入作品元数据（如作者历史表现）作为先验

3. **明显互评团证据** → 考虑引入简化版图检测算法

4. **评分质量差异大** → 考虑引入2维度的RTS（多样性与一致性）

**否则**：如果第一届运行良好，**不要为了创新而创新**，保持核心算法稳定，只做参数微调。

## 七、总结：为什么这个方案更好

### 7.1 相对于原方案的改进

1. **规避了所有已识别风险**：无收敛问题、无除零风险、无性能瓶颈

2. **完整的可执行性**：从算法到监控到降级，全链条覆盖

3. **平衡的艺术**：在公平性、可解释性、实施成本之间找到最佳平衡点

### 7.2 核心优势

- **透明可审计**：每个计算步骤都可追溯、可解释

- **渐进式演进**：为每一届比赛都预留了基于数据的优化空间

- **用户为中心**：所有设计决策都考虑了最终用户的认知和接受度

- **工程友好**：无复杂依赖，无高性能计算要求，适合创业团队实施

### 7.3 实施承诺

**向用户承诺**：

> "第一届，我们选择简单透明的算法，可能不是最完美的，但一定是最诚实的。我们会完整记录所有数据，并在赛后公开分析报告。您的每一次评分，都在帮助我们让下一届更公平。"

这个方案既尊重了技术文档中的专业意见，又充分考虑了"惊蛰计划第一届"的现实约束，是目前最可行、最公平、最有效的实施方案。
